{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "599d768a-31b5-42dc-88e2-99cd590bd002",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef5a6e88-6968-4f80-8a48-9369ef2171b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05d3fe85-0650-49b9-b7c4-6dada8f6c40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.186257</td>\n",
       "      <td>-0.058807</td>\n",
       "      <td>0.024632</td>\n",
       "      <td>-0.163933</td>\n",
       "      <td>-0.146699</td>\n",
       "      <td>0.035889</td>\n",
       "      <td>0.111708</td>\n",
       "      <td>-0.162861</td>\n",
       "      <td>0.028249</td>\n",
       "      <td>-0.098063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055629</td>\n",
       "      <td>-0.010358</td>\n",
       "      <td>0.125754</td>\n",
       "      <td>0.011648</td>\n",
       "      <td>0.079197</td>\n",
       "      <td>0.093215</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063431</td>\n",
       "      <td>-0.023597</td>\n",
       "      <td>0.068057</td>\n",
       "      <td>-0.252915</td>\n",
       "      <td>-0.061094</td>\n",
       "      <td>-0.027316</td>\n",
       "      <td>0.135747</td>\n",
       "      <td>-0.168147</td>\n",
       "      <td>0.091236</td>\n",
       "      <td>-0.078473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.014893</td>\n",
       "      <td>0.071721</td>\n",
       "      <td>0.018918</td>\n",
       "      <td>0.100032</td>\n",
       "      <td>-0.083042</td>\n",
       "      <td>0.088615</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034962</td>\n",
       "      <td>0.035816</td>\n",
       "      <td>-0.029753</td>\n",
       "      <td>-0.094607</td>\n",
       "      <td>-0.017576</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>0.040121</td>\n",
       "      <td>-0.007932</td>\n",
       "      <td>0.097872</td>\n",
       "      <td>-0.024042</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012415</td>\n",
       "      <td>0.015215</td>\n",
       "      <td>0.083808</td>\n",
       "      <td>0.031312</td>\n",
       "      <td>-0.056277</td>\n",
       "      <td>0.064702</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033772</td>\n",
       "      <td>0.085612</td>\n",
       "      <td>0.067488</td>\n",
       "      <td>-0.073953</td>\n",
       "      <td>-0.180646</td>\n",
       "      <td>-0.024512</td>\n",
       "      <td>0.242879</td>\n",
       "      <td>-0.023374</td>\n",
       "      <td>-0.059999</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078246</td>\n",
       "      <td>-0.032903</td>\n",
       "      <td>0.082949</td>\n",
       "      <td>-0.020659</td>\n",
       "      <td>0.082274</td>\n",
       "      <td>-0.050164</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.134305</td>\n",
       "      <td>0.062096</td>\n",
       "      <td>0.106920</td>\n",
       "      <td>-0.089327</td>\n",
       "      <td>0.117093</td>\n",
       "      <td>-0.077107</td>\n",
       "      <td>0.152579</td>\n",
       "      <td>0.047529</td>\n",
       "      <td>-0.015998</td>\n",
       "      <td>-0.110657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.094629</td>\n",
       "      <td>0.069718</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.048124</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>-0.016980</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.186257  -0.058807   0.024632  -0.163933  -0.146699   0.035889   \n",
       "1   0.063431  -0.023597   0.068057  -0.252915  -0.061094  -0.027316   \n",
       "2   0.034962   0.035816  -0.029753  -0.094607  -0.017576  -0.053074   \n",
       "3   0.033772   0.085612   0.067488  -0.073953  -0.180646  -0.024512   \n",
       "4   0.134305   0.062096   0.106920  -0.089327   0.117093  -0.077107   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_763  feature_764  \\\n",
       "0   0.111708  -0.162861   0.028249   -0.098063  ...     0.055629    -0.010358   \n",
       "1   0.135747  -0.168147   0.091236   -0.078473  ...    -0.014893     0.071721   \n",
       "2   0.040121  -0.007932   0.097872   -0.024042  ...     0.012415     0.015215   \n",
       "3   0.242879  -0.023374  -0.059999    0.002006  ...    -0.078246    -0.032903   \n",
       "4   0.152579   0.047529  -0.015998   -0.110657  ...    -0.094629     0.069718   \n",
       "\n",
       "   feature_765  feature_766  feature_767  feature_768  label_1  label_2  \\\n",
       "0     0.125754     0.011648     0.079197     0.093215       45      NaN   \n",
       "1     0.018918     0.100032    -0.083042     0.088615       45      NaN   \n",
       "2     0.083808     0.031312    -0.056277     0.064702       45      NaN   \n",
       "3     0.082949    -0.020659     0.082274    -0.050164       45      NaN   \n",
       "4     0.014379     0.048124     0.007586    -0.016980       45      NaN   \n",
       "\n",
       "   label_3  label_4  \n",
       "0        1        6  \n",
       "1        1        6  \n",
       "2        1        6  \n",
       "3        1        6  \n",
       "4        1        6  \n",
       "\n",
       "[5 rows x 772 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "320353c1-7193-4847-8241-4bfa1477bc26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1        0\n",
       "feature_2        0\n",
       "feature_3        0\n",
       "feature_4        0\n",
       "feature_5        0\n",
       "              ... \n",
       "feature_768      0\n",
       "label_1          0\n",
       "label_2        480\n",
       "label_3          0\n",
       "label_4          0\n",
       "Length: 772, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##check null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a84086ca-ee0b-4f3d-a77d-2aaa80b937ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]]\n",
    "X_train = df.drop(y_train, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa4f5417-46a0-4e3b-a090-8ee8c68c8716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.186257</td>\n",
       "      <td>-0.058807</td>\n",
       "      <td>0.024632</td>\n",
       "      <td>-0.163933</td>\n",
       "      <td>-0.146699</td>\n",
       "      <td>0.035889</td>\n",
       "      <td>0.111708</td>\n",
       "      <td>-0.162861</td>\n",
       "      <td>0.028249</td>\n",
       "      <td>-0.098063</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.135802</td>\n",
       "      <td>0.101059</td>\n",
       "      <td>0.128649</td>\n",
       "      <td>-0.187129</td>\n",
       "      <td>0.055629</td>\n",
       "      <td>-0.010358</td>\n",
       "      <td>0.125754</td>\n",
       "      <td>0.011648</td>\n",
       "      <td>0.079197</td>\n",
       "      <td>0.093215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.063431</td>\n",
       "      <td>-0.023597</td>\n",
       "      <td>0.068057</td>\n",
       "      <td>-0.252915</td>\n",
       "      <td>-0.061094</td>\n",
       "      <td>-0.027316</td>\n",
       "      <td>0.135747</td>\n",
       "      <td>-0.168147</td>\n",
       "      <td>0.091236</td>\n",
       "      <td>-0.078473</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032524</td>\n",
       "      <td>0.012977</td>\n",
       "      <td>0.090799</td>\n",
       "      <td>-0.254056</td>\n",
       "      <td>-0.014893</td>\n",
       "      <td>0.071721</td>\n",
       "      <td>0.018918</td>\n",
       "      <td>0.100032</td>\n",
       "      <td>-0.083042</td>\n",
       "      <td>0.088615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.034962</td>\n",
       "      <td>0.035816</td>\n",
       "      <td>-0.029753</td>\n",
       "      <td>-0.094607</td>\n",
       "      <td>-0.017576</td>\n",
       "      <td>-0.053074</td>\n",
       "      <td>0.040121</td>\n",
       "      <td>-0.007932</td>\n",
       "      <td>0.097872</td>\n",
       "      <td>-0.024042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016680</td>\n",
       "      <td>-0.015495</td>\n",
       "      <td>-0.003885</td>\n",
       "      <td>-0.106426</td>\n",
       "      <td>0.012415</td>\n",
       "      <td>0.015215</td>\n",
       "      <td>0.083808</td>\n",
       "      <td>0.031312</td>\n",
       "      <td>-0.056277</td>\n",
       "      <td>0.064702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.033772</td>\n",
       "      <td>0.085612</td>\n",
       "      <td>0.067488</td>\n",
       "      <td>-0.073953</td>\n",
       "      <td>-0.180646</td>\n",
       "      <td>-0.024512</td>\n",
       "      <td>0.242879</td>\n",
       "      <td>-0.023374</td>\n",
       "      <td>-0.059999</td>\n",
       "      <td>0.002006</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219269</td>\n",
       "      <td>0.065505</td>\n",
       "      <td>0.016679</td>\n",
       "      <td>0.047519</td>\n",
       "      <td>-0.078246</td>\n",
       "      <td>-0.032903</td>\n",
       "      <td>0.082949</td>\n",
       "      <td>-0.020659</td>\n",
       "      <td>0.082274</td>\n",
       "      <td>-0.050164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.134305</td>\n",
       "      <td>0.062096</td>\n",
       "      <td>0.106920</td>\n",
       "      <td>-0.089327</td>\n",
       "      <td>0.117093</td>\n",
       "      <td>-0.077107</td>\n",
       "      <td>0.152579</td>\n",
       "      <td>0.047529</td>\n",
       "      <td>-0.015998</td>\n",
       "      <td>-0.110657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228570</td>\n",
       "      <td>0.064493</td>\n",
       "      <td>0.177749</td>\n",
       "      <td>-0.117646</td>\n",
       "      <td>-0.094629</td>\n",
       "      <td>0.069718</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.048124</td>\n",
       "      <td>0.007586</td>\n",
       "      <td>-0.016980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28515</th>\n",
       "      <td>0.024453</td>\n",
       "      <td>0.044466</td>\n",
       "      <td>-0.049367</td>\n",
       "      <td>-0.065155</td>\n",
       "      <td>-0.109931</td>\n",
       "      <td>-0.089393</td>\n",
       "      <td>0.003823</td>\n",
       "      <td>0.036797</td>\n",
       "      <td>0.142065</td>\n",
       "      <td>0.010630</td>\n",
       "      <td>...</td>\n",
       "      <td>0.024859</td>\n",
       "      <td>0.034621</td>\n",
       "      <td>0.051483</td>\n",
       "      <td>0.055168</td>\n",
       "      <td>-0.037605</td>\n",
       "      <td>-0.009495</td>\n",
       "      <td>0.069628</td>\n",
       "      <td>-0.064233</td>\n",
       "      <td>-0.082123</td>\n",
       "      <td>0.068675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28516</th>\n",
       "      <td>0.016492</td>\n",
       "      <td>0.007850</td>\n",
       "      <td>0.004661</td>\n",
       "      <td>-0.068151</td>\n",
       "      <td>-0.120102</td>\n",
       "      <td>-0.018188</td>\n",
       "      <td>0.088983</td>\n",
       "      <td>-0.016272</td>\n",
       "      <td>0.057924</td>\n",
       "      <td>-0.091656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.067817</td>\n",
       "      <td>-0.003412</td>\n",
       "      <td>0.120643</td>\n",
       "      <td>-0.156379</td>\n",
       "      <td>-0.043655</td>\n",
       "      <td>-0.065877</td>\n",
       "      <td>0.114468</td>\n",
       "      <td>0.085360</td>\n",
       "      <td>-0.032404</td>\n",
       "      <td>0.076920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28517</th>\n",
       "      <td>0.024608</td>\n",
       "      <td>0.045056</td>\n",
       "      <td>0.011118</td>\n",
       "      <td>-0.055420</td>\n",
       "      <td>-0.180276</td>\n",
       "      <td>-0.075961</td>\n",
       "      <td>0.047853</td>\n",
       "      <td>0.043180</td>\n",
       "      <td>0.152698</td>\n",
       "      <td>-0.111217</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066240</td>\n",
       "      <td>0.146486</td>\n",
       "      <td>0.103236</td>\n",
       "      <td>0.060171</td>\n",
       "      <td>0.045422</td>\n",
       "      <td>-0.109505</td>\n",
       "      <td>-0.000356</td>\n",
       "      <td>0.022698</td>\n",
       "      <td>0.065250</td>\n",
       "      <td>0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28518</th>\n",
       "      <td>0.174154</td>\n",
       "      <td>-0.068870</td>\n",
       "      <td>0.058101</td>\n",
       "      <td>-0.120567</td>\n",
       "      <td>-0.237380</td>\n",
       "      <td>0.024585</td>\n",
       "      <td>0.187333</td>\n",
       "      <td>-0.100873</td>\n",
       "      <td>0.039363</td>\n",
       "      <td>-0.080888</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062747</td>\n",
       "      <td>0.092733</td>\n",
       "      <td>0.099706</td>\n",
       "      <td>0.045776</td>\n",
       "      <td>0.028609</td>\n",
       "      <td>-0.081717</td>\n",
       "      <td>0.089243</td>\n",
       "      <td>0.017368</td>\n",
       "      <td>0.044567</td>\n",
       "      <td>0.089306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>0.069458</td>\n",
       "      <td>0.102667</td>\n",
       "      <td>-0.010687</td>\n",
       "      <td>-0.054117</td>\n",
       "      <td>-0.171478</td>\n",
       "      <td>-0.154001</td>\n",
       "      <td>0.076675</td>\n",
       "      <td>0.025081</td>\n",
       "      <td>0.118611</td>\n",
       "      <td>-0.061732</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130062</td>\n",
       "      <td>0.153767</td>\n",
       "      <td>0.124336</td>\n",
       "      <td>-0.049092</td>\n",
       "      <td>0.118842</td>\n",
       "      <td>-0.177180</td>\n",
       "      <td>0.004411</td>\n",
       "      <td>0.034947</td>\n",
       "      <td>0.039597</td>\n",
       "      <td>0.031190</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28520 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0       0.186257  -0.058807   0.024632  -0.163933  -0.146699   0.035889   \n",
       "1       0.063431  -0.023597   0.068057  -0.252915  -0.061094  -0.027316   \n",
       "2       0.034962   0.035816  -0.029753  -0.094607  -0.017576  -0.053074   \n",
       "3       0.033772   0.085612   0.067488  -0.073953  -0.180646  -0.024512   \n",
       "4       0.134305   0.062096   0.106920  -0.089327   0.117093  -0.077107   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "28515   0.024453   0.044466  -0.049367  -0.065155  -0.109931  -0.089393   \n",
       "28516   0.016492   0.007850   0.004661  -0.068151  -0.120102  -0.018188   \n",
       "28517   0.024608   0.045056   0.011118  -0.055420  -0.180276  -0.075961   \n",
       "28518   0.174154  -0.068870   0.058101  -0.120567  -0.237380   0.024585   \n",
       "28519   0.069458   0.102667  -0.010687  -0.054117  -0.171478  -0.154001   \n",
       "\n",
       "       feature_7  feature_8  feature_9  feature_10  ...  feature_759  \\\n",
       "0       0.111708  -0.162861   0.028249   -0.098063  ...    -0.135802   \n",
       "1       0.135747  -0.168147   0.091236   -0.078473  ...    -0.032524   \n",
       "2       0.040121  -0.007932   0.097872   -0.024042  ...    -0.016680   \n",
       "3       0.242879  -0.023374  -0.059999    0.002006  ...    -0.219269   \n",
       "4       0.152579   0.047529  -0.015998   -0.110657  ...    -0.228570   \n",
       "...          ...        ...        ...         ...  ...          ...   \n",
       "28515   0.003823   0.036797   0.142065    0.010630  ...     0.024859   \n",
       "28516   0.088983  -0.016272   0.057924   -0.091656  ...    -0.067817   \n",
       "28517   0.047853   0.043180   0.152698   -0.111217  ...    -0.066240   \n",
       "28518   0.187333  -0.100873   0.039363   -0.080888  ...     0.062747   \n",
       "28519   0.076675   0.025081   0.118611   -0.061732  ...    -0.130062   \n",
       "\n",
       "       feature_760  feature_761  feature_762  feature_763  feature_764  \\\n",
       "0         0.101059     0.128649    -0.187129     0.055629    -0.010358   \n",
       "1         0.012977     0.090799    -0.254056    -0.014893     0.071721   \n",
       "2        -0.015495    -0.003885    -0.106426     0.012415     0.015215   \n",
       "3         0.065505     0.016679     0.047519    -0.078246    -0.032903   \n",
       "4         0.064493     0.177749    -0.117646    -0.094629     0.069718   \n",
       "...            ...          ...          ...          ...          ...   \n",
       "28515     0.034621     0.051483     0.055168    -0.037605    -0.009495   \n",
       "28516    -0.003412     0.120643    -0.156379    -0.043655    -0.065877   \n",
       "28517     0.146486     0.103236     0.060171     0.045422    -0.109505   \n",
       "28518     0.092733     0.099706     0.045776     0.028609    -0.081717   \n",
       "28519     0.153767     0.124336    -0.049092     0.118842    -0.177180   \n",
       "\n",
       "       feature_765  feature_766  feature_767  feature_768  \n",
       "0         0.125754     0.011648     0.079197     0.093215  \n",
       "1         0.018918     0.100032    -0.083042     0.088615  \n",
       "2         0.083808     0.031312    -0.056277     0.064702  \n",
       "3         0.082949    -0.020659     0.082274    -0.050164  \n",
       "4         0.014379     0.048124     0.007586    -0.016980  \n",
       "...            ...          ...          ...          ...  \n",
       "28515     0.069628    -0.064233    -0.082123     0.068675  \n",
       "28516     0.114468     0.085360    -0.032404     0.076920  \n",
       "28517    -0.000356     0.022698     0.065250     0.017646  \n",
       "28518     0.089243     0.017368     0.044567     0.089306  \n",
       "28519     0.004411     0.034947     0.039597     0.031190  \n",
       "\n",
       "[28520 rows x 768 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "727b29dc-1122-4c65-95ab-6280829e5a44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28515</th>\n",
       "      <td>39</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28516</th>\n",
       "      <td>39</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28517</th>\n",
       "      <td>39</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28518</th>\n",
       "      <td>39</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28519</th>\n",
       "      <td>39</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28520 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label_1  label_2  label_3  label_4\n",
       "0           45      NaN        1        6\n",
       "1           45      NaN        1        6\n",
       "2           45      NaN        1        6\n",
       "3           45      NaN        1        6\n",
       "4           45      NaN        1        6\n",
       "...        ...      ...      ...      ...\n",
       "28515       39     29.0        1        6\n",
       "28516       39     29.0        1        6\n",
       "28517       39     29.0        1        6\n",
       "28518       39     29.0        1        6\n",
       "28519       39     29.0        1        6\n",
       "\n",
       "[28520 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8c15f069-d371-4542-9a96-3807c6decbf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feature_1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.283908</td>\n",
       "      <td>0.142182</td>\n",
       "      <td>-0.338103</td>\n",
       "      <td>-0.178025</td>\n",
       "      <td>-0.207995</td>\n",
       "      <td>0.148884</td>\n",
       "      <td>0.052742</td>\n",
       "      <td>-0.315786</td>\n",
       "      <td>-0.155347</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002735</td>\n",
       "      <td>0.202713</td>\n",
       "      <td>-0.255096</td>\n",
       "      <td>-0.186352</td>\n",
       "      <td>0.169145</td>\n",
       "      <td>-0.030147</td>\n",
       "      <td>-0.055811</td>\n",
       "      <td>-0.031686</td>\n",
       "      <td>0.041166</td>\n",
       "      <td>0.023219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_2</th>\n",
       "      <td>-0.283908</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.085842</td>\n",
       "      <td>0.155011</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>0.082116</td>\n",
       "      <td>-0.069860</td>\n",
       "      <td>-0.000870</td>\n",
       "      <td>0.250169</td>\n",
       "      <td>0.192959</td>\n",
       "      <td>...</td>\n",
       "      <td>0.257924</td>\n",
       "      <td>-0.023016</td>\n",
       "      <td>-0.014792</td>\n",
       "      <td>-0.112536</td>\n",
       "      <td>-0.191086</td>\n",
       "      <td>0.022819</td>\n",
       "      <td>0.024157</td>\n",
       "      <td>0.037137</td>\n",
       "      <td>-0.035141</td>\n",
       "      <td>0.025806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_3</th>\n",
       "      <td>0.142182</td>\n",
       "      <td>-0.085842</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.145121</td>\n",
       "      <td>-0.003237</td>\n",
       "      <td>-0.056097</td>\n",
       "      <td>0.137698</td>\n",
       "      <td>0.120606</td>\n",
       "      <td>-0.215018</td>\n",
       "      <td>-0.255378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.128951</td>\n",
       "      <td>-0.317668</td>\n",
       "      <td>-0.209626</td>\n",
       "      <td>0.081598</td>\n",
       "      <td>0.240037</td>\n",
       "      <td>-0.055686</td>\n",
       "      <td>0.098467</td>\n",
       "      <td>0.014603</td>\n",
       "      <td>0.030263</td>\n",
       "      <td>-0.051158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_4</th>\n",
       "      <td>-0.338103</td>\n",
       "      <td>0.155011</td>\n",
       "      <td>0.145121</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.058212</td>\n",
       "      <td>-0.130674</td>\n",
       "      <td>-0.099220</td>\n",
       "      <td>0.064827</td>\n",
       "      <td>0.098506</td>\n",
       "      <td>-0.067288</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.211635</td>\n",
       "      <td>-0.362384</td>\n",
       "      <td>-0.144449</td>\n",
       "      <td>-0.000296</td>\n",
       "      <td>-0.088443</td>\n",
       "      <td>-0.316624</td>\n",
       "      <td>0.046853</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>-0.059081</td>\n",
       "      <td>-0.008024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_5</th>\n",
       "      <td>-0.178025</td>\n",
       "      <td>0.011385</td>\n",
       "      <td>-0.003237</td>\n",
       "      <td>0.058212</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060386</td>\n",
       "      <td>-0.048629</td>\n",
       "      <td>-0.092161</td>\n",
       "      <td>0.024778</td>\n",
       "      <td>0.219142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.210182</td>\n",
       "      <td>0.148122</td>\n",
       "      <td>0.199165</td>\n",
       "      <td>0.198393</td>\n",
       "      <td>-0.142673</td>\n",
       "      <td>0.181856</td>\n",
       "      <td>-0.070505</td>\n",
       "      <td>0.103229</td>\n",
       "      <td>0.106992</td>\n",
       "      <td>0.006422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feature_768</th>\n",
       "      <td>-0.030147</td>\n",
       "      <td>0.022819</td>\n",
       "      <td>-0.055686</td>\n",
       "      <td>-0.316624</td>\n",
       "      <td>0.181856</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>-0.398800</td>\n",
       "      <td>-0.131120</td>\n",
       "      <td>0.301206</td>\n",
       "      <td>0.234216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.221313</td>\n",
       "      <td>0.142108</td>\n",
       "      <td>0.234996</td>\n",
       "      <td>0.158833</td>\n",
       "      <td>-0.178095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.048178</td>\n",
       "      <td>0.018263</td>\n",
       "      <td>0.139805</td>\n",
       "      <td>0.024310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_1</th>\n",
       "      <td>-0.055811</td>\n",
       "      <td>0.024157</td>\n",
       "      <td>0.098467</td>\n",
       "      <td>0.046853</td>\n",
       "      <td>-0.070505</td>\n",
       "      <td>-0.021496</td>\n",
       "      <td>-0.024910</td>\n",
       "      <td>0.043663</td>\n",
       "      <td>-0.033741</td>\n",
       "      <td>-0.046304</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010398</td>\n",
       "      <td>-0.126097</td>\n",
       "      <td>-0.070339</td>\n",
       "      <td>-0.002718</td>\n",
       "      <td>0.104106</td>\n",
       "      <td>-0.048178</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.038758</td>\n",
       "      <td>-0.403477</td>\n",
       "      <td>-0.021115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_2</th>\n",
       "      <td>-0.031686</td>\n",
       "      <td>0.037137</td>\n",
       "      <td>0.014603</td>\n",
       "      <td>0.006841</td>\n",
       "      <td>0.103229</td>\n",
       "      <td>0.048361</td>\n",
       "      <td>-0.023677</td>\n",
       "      <td>-0.006038</td>\n",
       "      <td>-0.000270</td>\n",
       "      <td>-0.015349</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009239</td>\n",
       "      <td>0.013713</td>\n",
       "      <td>-0.037036</td>\n",
       "      <td>0.019229</td>\n",
       "      <td>-0.024101</td>\n",
       "      <td>0.018263</td>\n",
       "      <td>-0.038758</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.086053</td>\n",
       "      <td>0.242613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_3</th>\n",
       "      <td>0.041166</td>\n",
       "      <td>-0.035141</td>\n",
       "      <td>0.030263</td>\n",
       "      <td>-0.059081</td>\n",
       "      <td>0.106992</td>\n",
       "      <td>0.041350</td>\n",
       "      <td>0.038326</td>\n",
       "      <td>0.091699</td>\n",
       "      <td>0.012572</td>\n",
       "      <td>0.009689</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052200</td>\n",
       "      <td>0.089202</td>\n",
       "      <td>0.137891</td>\n",
       "      <td>-0.022264</td>\n",
       "      <td>-0.045734</td>\n",
       "      <td>0.139805</td>\n",
       "      <td>-0.403477</td>\n",
       "      <td>0.086053</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.016825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>label_4</th>\n",
       "      <td>0.023219</td>\n",
       "      <td>0.025806</td>\n",
       "      <td>-0.051158</td>\n",
       "      <td>-0.008024</td>\n",
       "      <td>0.006422</td>\n",
       "      <td>0.016311</td>\n",
       "      <td>-0.067295</td>\n",
       "      <td>-0.146392</td>\n",
       "      <td>0.012093</td>\n",
       "      <td>0.026688</td>\n",
       "      <td>...</td>\n",
       "      <td>0.119500</td>\n",
       "      <td>0.049514</td>\n",
       "      <td>-0.015315</td>\n",
       "      <td>0.017489</td>\n",
       "      <td>-0.018674</td>\n",
       "      <td>0.024310</td>\n",
       "      <td>-0.021115</td>\n",
       "      <td>0.242613</td>\n",
       "      <td>0.016825</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>772 rows × 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "feature_1     1.000000  -0.283908   0.142182  -0.338103  -0.178025  -0.207995   \n",
       "feature_2    -0.283908   1.000000  -0.085842   0.155011   0.011385   0.082116   \n",
       "feature_3     0.142182  -0.085842   1.000000   0.145121  -0.003237  -0.056097   \n",
       "feature_4    -0.338103   0.155011   0.145121   1.000000   0.058212  -0.130674   \n",
       "feature_5    -0.178025   0.011385  -0.003237   0.058212   1.000000   0.060386   \n",
       "...                ...        ...        ...        ...        ...        ...   \n",
       "feature_768  -0.030147   0.022819  -0.055686  -0.316624   0.181856   0.009531   \n",
       "label_1      -0.055811   0.024157   0.098467   0.046853  -0.070505  -0.021496   \n",
       "label_2      -0.031686   0.037137   0.014603   0.006841   0.103229   0.048361   \n",
       "label_3       0.041166  -0.035141   0.030263  -0.059081   0.106992   0.041350   \n",
       "label_4       0.023219   0.025806  -0.051158  -0.008024   0.006422   0.016311   \n",
       "\n",
       "             feature_7  feature_8  feature_9  feature_10  ...  feature_763  \\\n",
       "feature_1     0.148884   0.052742  -0.315786   -0.155347  ...    -0.002735   \n",
       "feature_2    -0.069860  -0.000870   0.250169    0.192959  ...     0.257924   \n",
       "feature_3     0.137698   0.120606  -0.215018   -0.255378  ...    -0.128951   \n",
       "feature_4    -0.099220   0.064827   0.098506   -0.067288  ...    -0.211635   \n",
       "feature_5    -0.048629  -0.092161   0.024778    0.219142  ...    -0.210182   \n",
       "...                ...        ...        ...         ...  ...          ...   \n",
       "feature_768  -0.398800  -0.131120   0.301206    0.234216  ...     0.221313   \n",
       "label_1      -0.024910   0.043663  -0.033741   -0.046304  ...    -0.010398   \n",
       "label_2      -0.023677  -0.006038  -0.000270   -0.015349  ...    -0.009239   \n",
       "label_3       0.038326   0.091699   0.012572    0.009689  ...     0.052200   \n",
       "label_4      -0.067295  -0.146392   0.012093    0.026688  ...     0.119500   \n",
       "\n",
       "             feature_764  feature_765  feature_766  feature_767  feature_768  \\\n",
       "feature_1       0.202713    -0.255096    -0.186352     0.169145    -0.030147   \n",
       "feature_2      -0.023016    -0.014792    -0.112536    -0.191086     0.022819   \n",
       "feature_3      -0.317668    -0.209626     0.081598     0.240037    -0.055686   \n",
       "feature_4      -0.362384    -0.144449    -0.000296    -0.088443    -0.316624   \n",
       "feature_5       0.148122     0.199165     0.198393    -0.142673     0.181856   \n",
       "...                  ...          ...          ...          ...          ...   \n",
       "feature_768     0.142108     0.234996     0.158833    -0.178095     1.000000   \n",
       "label_1        -0.126097    -0.070339    -0.002718     0.104106    -0.048178   \n",
       "label_2         0.013713    -0.037036     0.019229    -0.024101     0.018263   \n",
       "label_3         0.089202     0.137891    -0.022264    -0.045734     0.139805   \n",
       "label_4         0.049514    -0.015315     0.017489    -0.018674     0.024310   \n",
       "\n",
       "              label_1   label_2   label_3   label_4  \n",
       "feature_1   -0.055811 -0.031686  0.041166  0.023219  \n",
       "feature_2    0.024157  0.037137 -0.035141  0.025806  \n",
       "feature_3    0.098467  0.014603  0.030263 -0.051158  \n",
       "feature_4    0.046853  0.006841 -0.059081 -0.008024  \n",
       "feature_5   -0.070505  0.103229  0.106992  0.006422  \n",
       "...               ...       ...       ...       ...  \n",
       "feature_768 -0.048178  0.018263  0.139805  0.024310  \n",
       "label_1      1.000000 -0.038758 -0.403477 -0.021115  \n",
       "label_2     -0.038758  1.000000  0.086053  0.242613  \n",
       "label_3     -0.403477  0.086053  1.000000  0.016825  \n",
       "label_4     -0.021115  0.242613  0.016825  1.000000  \n",
       "\n",
       "[772 rows x 772 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "9866970b-8b1b-40af-ae8d-671f9543a4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv('valid.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e5c2ab19-1c81-4076-b8ab-173c085d3f7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.085129</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>-0.029872</td>\n",
       "      <td>-0.104609</td>\n",
       "      <td>-0.191291</td>\n",
       "      <td>-0.025511</td>\n",
       "      <td>0.029381</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.079207</td>\n",
       "      <td>-0.012729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.026701</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.052219</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.102033</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.222652</td>\n",
       "      <td>-0.094210</td>\n",
       "      <td>-0.056387</td>\n",
       "      <td>-0.210214</td>\n",
       "      <td>-0.294624</td>\n",
       "      <td>-0.032355</td>\n",
       "      <td>-0.069078</td>\n",
       "      <td>-0.172146</td>\n",
       "      <td>0.056509</td>\n",
       "      <td>-0.126757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.041096</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>0.142623</td>\n",
       "      <td>-0.011882</td>\n",
       "      <td>0.005219</td>\n",
       "      <td>0.143616</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.072147</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>-0.017664</td>\n",
       "      <td>-0.070988</td>\n",
       "      <td>-0.098729</td>\n",
       "      <td>0.018534</td>\n",
       "      <td>0.028282</td>\n",
       "      <td>-0.064789</td>\n",
       "      <td>0.094686</td>\n",
       "      <td>-0.067313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064602</td>\n",
       "      <td>-0.018653</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>-0.078994</td>\n",
       "      <td>0.060903</td>\n",
       "      <td>0.064752</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026623</td>\n",
       "      <td>0.052005</td>\n",
       "      <td>-0.006921</td>\n",
       "      <td>-0.075105</td>\n",
       "      <td>-0.074829</td>\n",
       "      <td>-0.031380</td>\n",
       "      <td>0.012402</td>\n",
       "      <td>-0.043555</td>\n",
       "      <td>0.073825</td>\n",
       "      <td>-0.050979</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005655</td>\n",
       "      <td>0.015477</td>\n",
       "      <td>0.064209</td>\n",
       "      <td>0.025045</td>\n",
       "      <td>-0.049599</td>\n",
       "      <td>0.078412</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.112069</td>\n",
       "      <td>0.113702</td>\n",
       "      <td>0.044343</td>\n",
       "      <td>0.010162</td>\n",
       "      <td>-0.169193</td>\n",
       "      <td>-0.099847</td>\n",
       "      <td>0.195957</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>0.024582</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.118097</td>\n",
       "      <td>-0.043349</td>\n",
       "      <td>0.036754</td>\n",
       "      <td>-0.023065</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>-0.132566</td>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 772 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.085129   0.000378  -0.029872  -0.104609  -0.191291  -0.025511   \n",
       "1   0.222652  -0.094210  -0.056387  -0.210214  -0.294624  -0.032355   \n",
       "2   0.072147   0.023575  -0.017664  -0.070988  -0.098729   0.018534   \n",
       "3   0.026623   0.052005  -0.006921  -0.075105  -0.074829  -0.031380   \n",
       "4   0.112069   0.113702   0.044343   0.010162  -0.169193  -0.099847   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_763  feature_764  \\\n",
       "0   0.029381   0.006177   0.079207   -0.012729  ...    -0.026701     0.003306   \n",
       "1  -0.069078  -0.172146   0.056509   -0.126757  ...    -0.041096     0.013654   \n",
       "2   0.028282  -0.064789   0.094686   -0.067313  ...    -0.064602    -0.018653   \n",
       "3   0.012402  -0.043555   0.073825   -0.050979  ...    -0.005655     0.015477   \n",
       "4   0.195957   0.051861   0.024582    0.001314  ...    -0.118097    -0.043349   \n",
       "\n",
       "   feature_765  feature_766  feature_767  feature_768  label_1  label_2  \\\n",
       "0     0.052219     0.000784     0.004527     0.102033       45      NaN   \n",
       "1     0.142623    -0.011882     0.005219     0.143616       45      NaN   \n",
       "2     0.013636    -0.078994     0.060903     0.064752       45      NaN   \n",
       "3     0.064209     0.025045    -0.049599     0.078412       45      NaN   \n",
       "4     0.036754    -0.023065     0.007358    -0.132566       45      NaN   \n",
       "\n",
       "   label_3  label_4  \n",
       "0        1        6  \n",
       "1        1        6  \n",
       "2        1        6  \n",
       "3        1        6  \n",
       "4        1        6  \n",
       "\n",
       "[5 rows x 772 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6bbf21f-103e-4787-94f7-f1446bf4c830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1       0\n",
       "feature_2       0\n",
       "feature_3       0\n",
       "feature_4       0\n",
       "feature_5       0\n",
       "               ..\n",
       "feature_768     0\n",
       "label_1         0\n",
       "label_2        14\n",
       "label_3         0\n",
       "label_4         0\n",
       "Length: 772, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de2d1465-c851-4d91-876c-e8dd9a3f645c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid = valid_df[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]]\n",
    "X_valid = valid_df.drop(y_valid, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81814549-3231-48d5-bbdf-00de25859801",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.085129</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>-0.029872</td>\n",
       "      <td>-0.104609</td>\n",
       "      <td>-0.191291</td>\n",
       "      <td>-0.025511</td>\n",
       "      <td>0.029381</td>\n",
       "      <td>0.006177</td>\n",
       "      <td>0.079207</td>\n",
       "      <td>-0.012729</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020899</td>\n",
       "      <td>0.087778</td>\n",
       "      <td>0.083750</td>\n",
       "      <td>0.111214</td>\n",
       "      <td>-0.026701</td>\n",
       "      <td>0.003306</td>\n",
       "      <td>0.052219</td>\n",
       "      <td>0.000784</td>\n",
       "      <td>0.004527</td>\n",
       "      <td>0.102033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.222652</td>\n",
       "      <td>-0.094210</td>\n",
       "      <td>-0.056387</td>\n",
       "      <td>-0.210214</td>\n",
       "      <td>-0.294624</td>\n",
       "      <td>-0.032355</td>\n",
       "      <td>-0.069078</td>\n",
       "      <td>-0.172146</td>\n",
       "      <td>0.056509</td>\n",
       "      <td>-0.126757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.159676</td>\n",
       "      <td>0.134823</td>\n",
       "      <td>0.139934</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>-0.041096</td>\n",
       "      <td>0.013654</td>\n",
       "      <td>0.142623</td>\n",
       "      <td>-0.011882</td>\n",
       "      <td>0.005219</td>\n",
       "      <td>0.143616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.072147</td>\n",
       "      <td>0.023575</td>\n",
       "      <td>-0.017664</td>\n",
       "      <td>-0.070988</td>\n",
       "      <td>-0.098729</td>\n",
       "      <td>0.018534</td>\n",
       "      <td>0.028282</td>\n",
       "      <td>-0.064789</td>\n",
       "      <td>0.094686</td>\n",
       "      <td>-0.067313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.072512</td>\n",
       "      <td>0.082791</td>\n",
       "      <td>0.017780</td>\n",
       "      <td>0.030908</td>\n",
       "      <td>-0.064602</td>\n",
       "      <td>-0.018653</td>\n",
       "      <td>0.013636</td>\n",
       "      <td>-0.078994</td>\n",
       "      <td>0.060903</td>\n",
       "      <td>0.064752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026623</td>\n",
       "      <td>0.052005</td>\n",
       "      <td>-0.006921</td>\n",
       "      <td>-0.075105</td>\n",
       "      <td>-0.074829</td>\n",
       "      <td>-0.031380</td>\n",
       "      <td>0.012402</td>\n",
       "      <td>-0.043555</td>\n",
       "      <td>0.073825</td>\n",
       "      <td>-0.050979</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012509</td>\n",
       "      <td>0.010695</td>\n",
       "      <td>0.019255</td>\n",
       "      <td>0.010389</td>\n",
       "      <td>-0.005655</td>\n",
       "      <td>0.015477</td>\n",
       "      <td>0.064209</td>\n",
       "      <td>0.025045</td>\n",
       "      <td>-0.049599</td>\n",
       "      <td>0.078412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.112069</td>\n",
       "      <td>0.113702</td>\n",
       "      <td>0.044343</td>\n",
       "      <td>0.010162</td>\n",
       "      <td>-0.169193</td>\n",
       "      <td>-0.099847</td>\n",
       "      <td>0.195957</td>\n",
       "      <td>0.051861</td>\n",
       "      <td>0.024582</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.173597</td>\n",
       "      <td>0.247099</td>\n",
       "      <td>0.101261</td>\n",
       "      <td>0.127192</td>\n",
       "      <td>-0.118097</td>\n",
       "      <td>-0.043349</td>\n",
       "      <td>0.036754</td>\n",
       "      <td>-0.023065</td>\n",
       "      <td>0.007358</td>\n",
       "      <td>-0.132566</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.085129   0.000378  -0.029872  -0.104609  -0.191291  -0.025511   \n",
       "1   0.222652  -0.094210  -0.056387  -0.210214  -0.294624  -0.032355   \n",
       "2   0.072147   0.023575  -0.017664  -0.070988  -0.098729   0.018534   \n",
       "3   0.026623   0.052005  -0.006921  -0.075105  -0.074829  -0.031380   \n",
       "4   0.112069   0.113702   0.044343   0.010162  -0.169193  -0.099847   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_759  feature_760  \\\n",
       "0   0.029381   0.006177   0.079207   -0.012729  ...    -0.020899     0.087778   \n",
       "1  -0.069078  -0.172146   0.056509   -0.126757  ...    -0.159676     0.134823   \n",
       "2   0.028282  -0.064789   0.094686   -0.067313  ...    -0.072512     0.082791   \n",
       "3   0.012402  -0.043555   0.073825   -0.050979  ...     0.012509     0.010695   \n",
       "4   0.195957   0.051861   0.024582    0.001314  ...    -0.173597     0.247099   \n",
       "\n",
       "   feature_761  feature_762  feature_763  feature_764  feature_765  \\\n",
       "0     0.083750     0.111214    -0.026701     0.003306     0.052219   \n",
       "1     0.139934     0.035135    -0.041096     0.013654     0.142623   \n",
       "2     0.017780     0.030908    -0.064602    -0.018653     0.013636   \n",
       "3     0.019255     0.010389    -0.005655     0.015477     0.064209   \n",
       "4     0.101261     0.127192    -0.118097    -0.043349     0.036754   \n",
       "\n",
       "   feature_766  feature_767  feature_768  \n",
       "0     0.000784     0.004527     0.102033  \n",
       "1    -0.011882     0.005219     0.143616  \n",
       "2    -0.078994     0.060903     0.064752  \n",
       "3     0.025045    -0.049599     0.078412  \n",
       "4    -0.023065     0.007358    -0.132566  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "890b0c91-da90-4756-bca6-95decbec1b74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label_1  label_2  label_3  label_4\n",
       "0       45      NaN        1        6\n",
       "1       45      NaN        1        6\n",
       "2       45      NaN        1        6\n",
       "3       45      NaN        1        6\n",
       "4       45      NaN        1        6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbfd41b8-3fc2-4c1c-bcfa-efd2ac3a7959",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbb792-8d52-42f9-ac9b-0032628c9850",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe69d98c-48e9-4f14-9fa9-46cdcea624e0",
   "metadata": {},
   "source": [
    "# KNN Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3d2760f1-9555-4a0f-bb53-43da1995bed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def try_knn(train_x, train_y, valid_x, valid_y):\n",
    "    grid_params = { 'n_neighbors' : [3,5,7,15],\n",
    "               'weights' : ['uniform','distance']}\n",
    "    gs = GridSearchCV(KNeighborsClassifier(), grid_params, verbose = 1, cv=3, n_jobs = -1)\n",
    "    g_res = gs.fit(train_x, train_y)\n",
    "    print(f\"Best Hyperparameters:\",gs.best_params_)\n",
    "    # Get the best k-NN model with the optimal hyperparameters\n",
    "    best_knn = gs.best_estimator_\n",
    "    # Evaluate the best model on the test data\n",
    "    accuracy = best_knn.score(valid_x, valid_y)\n",
    "    print(f\"Accuracy for KNN {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2e8bb6-1c2e-4bab-b2db-b993763f6085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b98508b-b0fb-4880-ab33-83c53c5d0853",
   "metadata": {},
   "source": [
    "# SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14b9bfeb-e45a-471d-96c2-526fa6852c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def try_svm(train_x, train_y, valid_x, valid_y):\n",
    "    clf = svm.SVC()\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(valid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with default settings (RBF - exponential kernal) \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.LinearSVC(dual=\"auto\")\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(valid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of Linear SVM (one-vs-the-rest) \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='linear')\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(valid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with linear kernal function \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='sigmoid')\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(valid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with sigmoid kernal function \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='poly',degree =2)\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(valid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with polynomial kernal function with degree 2 \", accuracy_score(valid_y, y_pred))\n",
    "    \n",
    "    clf = svm.SVC(kernel='poly',degree =2)\n",
    "    clf.fit(train_x, train_y)\n",
    "    X_valid_contiguous = np.ascontiguousarray(valid_x)\n",
    "    y_pred = clf.predict(X_valid_contiguous)\n",
    "    print(f\"Accuracy Score of SVM with polynomial kernal function with degree 3 \", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaa91d6-d63c-4f46-8a44-0385f12de849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc269b21-4ab2-4655-a766-2c1bf8cdd7e1",
   "metadata": {},
   "source": [
    "# xgBoost Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b935109-4c73-4b95-9310-a61ed6843def",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def try_xgBoost(train_x, train_y, vaid_x, valid_y):\n",
    "    # Create an XGBoost classifier for multi-class classification\n",
    "    clf = xgb.XGBClassifier(\n",
    "    objective='multi:softmax',  # Set the objective for multi-class classification\n",
    "    num_class=len(np.unique(train_y)),  # Number of classes\n",
    "    random_state=42\n",
    "    )\n",
    "    le = LabelEncoder()\n",
    "    train_y = le.fit_transform(train_y)\n",
    "    clf.fit(train_x, train_y)\n",
    "    y_pred = clf.predict(vaid_x)\n",
    "    y_pred = le.inverse_transform(y_pred)\n",
    "    print(f\"Accuracy Score of XG Boost\", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4f0c01-f889-4b0b-a29c-c136440df249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb0ea55a-9e12-4ab5-85fc-c91fd8f90fa6",
   "metadata": {},
   "source": [
    "# Rondom Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "339cfddd-ec25-46f0-83cb-c2868075ac86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def try_random_forest(train_x, train_y, vaid_x, valid_y):\n",
    "    clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    clf.fit(train_x, train_y)\n",
    "    y_pred = clf.predict(vaid_x)\n",
    "    print(f\"Accuracy Score of Random Forest\", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2254adbc-16e3-4dcf-8900-9ecb7b609568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41067ebd-5553-4e1d-8673-c20ec661ca6c",
   "metadata": {},
   "source": [
    "# Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "01972a52-f57d-4cdd-a7bb-90f1c06ea008",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def try_logistic(train_x, train_y, vaid_x, valid_y):\n",
    "    for i in [\"lbfgs\",\"newton-cg\",\"sag\",\"saga\"]:\n",
    "        logistic_regression = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "        logistic_regression.fit(train_x,train_y)\n",
    "        y_pred = logistic_regression.predict(vaid_x)\n",
    "        print(f\"Accuracy Score of Logistic Regression with solver {i}\", accuracy_score(valid_y, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c4b11b-0cee-4c37-a009-8d7bb293bcad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b77901-b66c-442d-accb-47034087bd89",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4df941a9-fa5a-431c-909f-3d605fb9b803",
   "metadata": {},
   "source": [
    "# Predict a probability for the TARGET variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "380dec34-505f-4095-88d7-12c7ef05caf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.187868</td>\n",
       "      <td>-0.009268</td>\n",
       "      <td>0.039846</td>\n",
       "      <td>-0.102515</td>\n",
       "      <td>-0.109121</td>\n",
       "      <td>-0.079769</td>\n",
       "      <td>0.061295</td>\n",
       "      <td>-0.042890</td>\n",
       "      <td>0.099860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043647</td>\n",
       "      <td>0.061174</td>\n",
       "      <td>0.026771</td>\n",
       "      <td>-0.092734</td>\n",
       "      <td>-0.052383</td>\n",
       "      <td>-0.055526</td>\n",
       "      <td>0.029101</td>\n",
       "      <td>0.041857</td>\n",
       "      <td>-0.027872</td>\n",
       "      <td>0.099500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.122119</td>\n",
       "      <td>0.019015</td>\n",
       "      <td>0.134483</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>-0.157884</td>\n",
       "      <td>-0.033332</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>-0.016869</td>\n",
       "      <td>-0.014088</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179798</td>\n",
       "      <td>-0.027611</td>\n",
       "      <td>0.240023</td>\n",
       "      <td>-0.005648</td>\n",
       "      <td>-0.057537</td>\n",
       "      <td>0.023922</td>\n",
       "      <td>-0.038126</td>\n",
       "      <td>-0.015171</td>\n",
       "      <td>-0.006270</td>\n",
       "      <td>-0.003790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.079187</td>\n",
       "      <td>0.146195</td>\n",
       "      <td>-0.001316</td>\n",
       "      <td>-0.085596</td>\n",
       "      <td>-0.261093</td>\n",
       "      <td>-0.021620</td>\n",
       "      <td>0.268898</td>\n",
       "      <td>-0.103950</td>\n",
       "      <td>0.068976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075460</td>\n",
       "      <td>0.037346</td>\n",
       "      <td>0.124254</td>\n",
       "      <td>-0.369695</td>\n",
       "      <td>-0.056773</td>\n",
       "      <td>-0.028471</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>-0.065683</td>\n",
       "      <td>-0.047366</td>\n",
       "      <td>-0.121744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.231196</td>\n",
       "      <td>0.021558</td>\n",
       "      <td>0.215534</td>\n",
       "      <td>-0.210258</td>\n",
       "      <td>-0.158189</td>\n",
       "      <td>0.041621</td>\n",
       "      <td>0.240254</td>\n",
       "      <td>-0.068112</td>\n",
       "      <td>-0.017550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.141642</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>0.031547</td>\n",
       "      <td>-0.010762</td>\n",
       "      <td>-0.169036</td>\n",
       "      <td>-0.030963</td>\n",
       "      <td>0.086698</td>\n",
       "      <td>0.114194</td>\n",
       "      <td>-0.036775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.020412</td>\n",
       "      <td>0.063732</td>\n",
       "      <td>-0.065506</td>\n",
       "      <td>-0.089598</td>\n",
       "      <td>-0.130788</td>\n",
       "      <td>-0.018809</td>\n",
       "      <td>0.119304</td>\n",
       "      <td>-0.057494</td>\n",
       "      <td>0.094714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001969</td>\n",
       "      <td>-0.003025</td>\n",
       "      <td>-0.021156</td>\n",
       "      <td>-0.136993</td>\n",
       "      <td>-0.003615</td>\n",
       "      <td>0.036371</td>\n",
       "      <td>0.048715</td>\n",
       "      <td>-0.002688</td>\n",
       "      <td>-0.016957</td>\n",
       "      <td>-0.004331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 769 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   1   0.187868  -0.009268   0.039846  -0.102515  -0.109121  -0.079769   \n",
       "1   2   0.122119   0.019015   0.134483   0.007949  -0.157884  -0.033332   \n",
       "2   3   0.079187   0.146195  -0.001316  -0.085596  -0.261093  -0.021620   \n",
       "3   4   0.231196   0.021558   0.215534  -0.210258  -0.158189   0.041621   \n",
       "4   5   0.020412   0.063732  -0.065506  -0.089598  -0.130788  -0.018809   \n",
       "\n",
       "   feature_7  feature_8  feature_9  ...  feature_759  feature_760  \\\n",
       "0   0.061295  -0.042890   0.099860  ...     0.043647     0.061174   \n",
       "1   0.044334  -0.016869  -0.014088  ...    -0.179798    -0.027611   \n",
       "2   0.268898  -0.103950   0.068976  ...    -0.075460     0.037346   \n",
       "3   0.240254  -0.068112  -0.017550  ...     0.083334     0.141642   \n",
       "4   0.119304  -0.057494   0.094714  ...    -0.001969    -0.003025   \n",
       "\n",
       "   feature_761  feature_762  feature_763  feature_764  feature_765  \\\n",
       "0     0.026771    -0.092734    -0.052383    -0.055526     0.029101   \n",
       "1     0.240023    -0.005648    -0.057537     0.023922    -0.038126   \n",
       "2     0.124254    -0.369695    -0.056773    -0.028471     0.019971   \n",
       "3    -0.007219     0.031547    -0.010762    -0.169036    -0.030963   \n",
       "4    -0.021156    -0.136993    -0.003615     0.036371     0.048715   \n",
       "\n",
       "   feature_766  feature_767  feature_768  \n",
       "0     0.041857    -0.027872     0.099500  \n",
       "1    -0.015171    -0.006270    -0.003790  \n",
       "2    -0.065683    -0.047366    -0.121744  \n",
       "3     0.086698     0.114194    -0.036775  \n",
       "4    -0.002688    -0.016957    -0.004331  \n",
       "\n",
       "[5 rows x 769 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df=pd.read_csv('test.csv')\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73446afd-292d-4ce0-bd69-13ce9a0187a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop([\"ID\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6c686240-5a9a-4a22-aee2-e6745a0c10d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature_1</th>\n",
       "      <th>feature_2</th>\n",
       "      <th>feature_3</th>\n",
       "      <th>feature_4</th>\n",
       "      <th>feature_5</th>\n",
       "      <th>feature_6</th>\n",
       "      <th>feature_7</th>\n",
       "      <th>feature_8</th>\n",
       "      <th>feature_9</th>\n",
       "      <th>feature_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_759</th>\n",
       "      <th>feature_760</th>\n",
       "      <th>feature_761</th>\n",
       "      <th>feature_762</th>\n",
       "      <th>feature_763</th>\n",
       "      <th>feature_764</th>\n",
       "      <th>feature_765</th>\n",
       "      <th>feature_766</th>\n",
       "      <th>feature_767</th>\n",
       "      <th>feature_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.187868</td>\n",
       "      <td>-0.009268</td>\n",
       "      <td>0.039846</td>\n",
       "      <td>-0.102515</td>\n",
       "      <td>-0.109121</td>\n",
       "      <td>-0.079769</td>\n",
       "      <td>0.061295</td>\n",
       "      <td>-0.042890</td>\n",
       "      <td>0.099860</td>\n",
       "      <td>-0.066319</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043647</td>\n",
       "      <td>0.061174</td>\n",
       "      <td>0.026771</td>\n",
       "      <td>-0.092734</td>\n",
       "      <td>-0.052383</td>\n",
       "      <td>-0.055526</td>\n",
       "      <td>0.029101</td>\n",
       "      <td>0.041857</td>\n",
       "      <td>-0.027872</td>\n",
       "      <td>0.099500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.122119</td>\n",
       "      <td>0.019015</td>\n",
       "      <td>0.134483</td>\n",
       "      <td>0.007949</td>\n",
       "      <td>-0.157884</td>\n",
       "      <td>-0.033332</td>\n",
       "      <td>0.044334</td>\n",
       "      <td>-0.016869</td>\n",
       "      <td>-0.014088</td>\n",
       "      <td>-0.060542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.179798</td>\n",
       "      <td>-0.027611</td>\n",
       "      <td>0.240023</td>\n",
       "      <td>-0.005648</td>\n",
       "      <td>-0.057537</td>\n",
       "      <td>0.023922</td>\n",
       "      <td>-0.038126</td>\n",
       "      <td>-0.015171</td>\n",
       "      <td>-0.006270</td>\n",
       "      <td>-0.003790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.079187</td>\n",
       "      <td>0.146195</td>\n",
       "      <td>-0.001316</td>\n",
       "      <td>-0.085596</td>\n",
       "      <td>-0.261093</td>\n",
       "      <td>-0.021620</td>\n",
       "      <td>0.268898</td>\n",
       "      <td>-0.103950</td>\n",
       "      <td>0.068976</td>\n",
       "      <td>-0.062388</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.075460</td>\n",
       "      <td>0.037346</td>\n",
       "      <td>0.124254</td>\n",
       "      <td>-0.369695</td>\n",
       "      <td>-0.056773</td>\n",
       "      <td>-0.028471</td>\n",
       "      <td>0.019971</td>\n",
       "      <td>-0.065683</td>\n",
       "      <td>-0.047366</td>\n",
       "      <td>-0.121744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.231196</td>\n",
       "      <td>0.021558</td>\n",
       "      <td>0.215534</td>\n",
       "      <td>-0.210258</td>\n",
       "      <td>-0.158189</td>\n",
       "      <td>0.041621</td>\n",
       "      <td>0.240254</td>\n",
       "      <td>-0.068112</td>\n",
       "      <td>-0.017550</td>\n",
       "      <td>-0.233767</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083334</td>\n",
       "      <td>0.141642</td>\n",
       "      <td>-0.007219</td>\n",
       "      <td>0.031547</td>\n",
       "      <td>-0.010762</td>\n",
       "      <td>-0.169036</td>\n",
       "      <td>-0.030963</td>\n",
       "      <td>0.086698</td>\n",
       "      <td>0.114194</td>\n",
       "      <td>-0.036775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020412</td>\n",
       "      <td>0.063732</td>\n",
       "      <td>-0.065506</td>\n",
       "      <td>-0.089598</td>\n",
       "      <td>-0.130788</td>\n",
       "      <td>-0.018809</td>\n",
       "      <td>0.119304</td>\n",
       "      <td>-0.057494</td>\n",
       "      <td>0.094714</td>\n",
       "      <td>-0.047923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001969</td>\n",
       "      <td>-0.003025</td>\n",
       "      <td>-0.021156</td>\n",
       "      <td>-0.136993</td>\n",
       "      <td>-0.003615</td>\n",
       "      <td>0.036371</td>\n",
       "      <td>0.048715</td>\n",
       "      <td>-0.002688</td>\n",
       "      <td>-0.016957</td>\n",
       "      <td>-0.004331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   feature_1  feature_2  feature_3  feature_4  feature_5  feature_6  \\\n",
       "0   0.187868  -0.009268   0.039846  -0.102515  -0.109121  -0.079769   \n",
       "1   0.122119   0.019015   0.134483   0.007949  -0.157884  -0.033332   \n",
       "2   0.079187   0.146195  -0.001316  -0.085596  -0.261093  -0.021620   \n",
       "3   0.231196   0.021558   0.215534  -0.210258  -0.158189   0.041621   \n",
       "4   0.020412   0.063732  -0.065506  -0.089598  -0.130788  -0.018809   \n",
       "\n",
       "   feature_7  feature_8  feature_9  feature_10  ...  feature_759  feature_760  \\\n",
       "0   0.061295  -0.042890   0.099860   -0.066319  ...     0.043647     0.061174   \n",
       "1   0.044334  -0.016869  -0.014088   -0.060542  ...    -0.179798    -0.027611   \n",
       "2   0.268898  -0.103950   0.068976   -0.062388  ...    -0.075460     0.037346   \n",
       "3   0.240254  -0.068112  -0.017550   -0.233767  ...     0.083334     0.141642   \n",
       "4   0.119304  -0.057494   0.094714   -0.047923  ...    -0.001969    -0.003025   \n",
       "\n",
       "   feature_761  feature_762  feature_763  feature_764  feature_765  \\\n",
       "0     0.026771    -0.092734    -0.052383    -0.055526     0.029101   \n",
       "1     0.240023    -0.005648    -0.057537     0.023922    -0.038126   \n",
       "2     0.124254    -0.369695    -0.056773    -0.028471     0.019971   \n",
       "3    -0.007219     0.031547    -0.010762    -0.169036    -0.030963   \n",
       "4    -0.021156    -0.136993    -0.003615     0.036371     0.048715   \n",
       "\n",
       "   feature_766  feature_767  feature_768  \n",
       "0     0.041857    -0.027872     0.099500  \n",
       "1    -0.015171    -0.006270    -0.003790  \n",
       "2    -0.065683    -0.047366    -0.121744  \n",
       "3     0.086698     0.114194    -0.036775  \n",
       "4    -0.002688    -0.016957    -0.004331  \n",
       "\n",
       "[5 rows x 768 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2b571355-0340-4f6a-bff0-45d0be659a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1      0\n",
       "feature_2      0\n",
       "feature_3      0\n",
       "feature_4      0\n",
       "feature_5      0\n",
       "              ..\n",
       "feature_764    0\n",
       "feature_765    0\n",
       "feature_766    0\n",
       "feature_767    0\n",
       "feature_768    0\n",
       "Length: 768, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063a3937-37b0-48ce-ae32-158e2dfa27b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4a5327e-712e-490c-92e3-7d46a8dc360e",
   "metadata": {},
   "source": [
    "# Label_1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e132e3-162e-4000-b2cf-bbefb7edc3e5",
   "metadata": {},
   "source": [
    "# Use the SVM Model for label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "352159dc-4a4a-45ff-84eb-4f26cad7c450",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Linear SVM (one-vs-the-rest)  0.9826666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with linear kernal function  0.9746666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with sigmoid kernal function  0.8973333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 3  0.956\n"
     ]
    }
   ],
   "source": [
    "try_svm(X_train,y_train[\"label_1\"],X_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96a5454-54c0-4592-84c3-2ccec74616ad",
   "metadata": {},
   "source": [
    "# Use the KNN Model for label_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ab99291a-4537-4bf3-b1df-9c51fac3f29a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.948\n"
     ]
    }
   ],
   "source": [
    "try_knn(X_train,y_train[\"label_1\"],X_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7581c08-ce0d-4107-bf13-8b738828afa0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aeed95cb-fbff-4455-8123-35cb2a8e7ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.9026666666666666\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(X_train,y_train[\"label_1\"],X_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbbcba9-34ce-46b4-8323-041b77cb699b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "feb548d5-b899-4a5e-9958-60e56dd0d43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.9066666666666666\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(X_train,y_train[\"label_1\"],X_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a97af6-c07b-4f6b-ad88-d31ca88a7e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b49154e8-1018-4c29-8233-7db91500a4a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver newton-cg 0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver sag 0.972\n",
      "Accuracy Score of Logistic Regression with solver saga 0.972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "try_logistic(X_train,y_train[\"label_1\"],X_valid,y_valid[\"label_1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7ed0c-b1eb-42aa-a437-369236fdbdf0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d930ade8-8324-4c4b-9ea3-dc73273be04f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e62d22a9-e985-47a7-8ebb-fa11b7a19951",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a381bc71-50c9-4faf-a913-b0d63aad2d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1c9140d3-1551-4297-b7c3-4294ed1c7643",
   "metadata": {},
   "source": [
    "# For label_1 we get best accuracy(0.98266) when using the Linear SVM\n",
    "So we can use this method to predict the values for test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac583264-13a0-45c8-9feb-fbdee7a7c763",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([26, 18, 16,  7, 58, 46,  7, 22, 29, 26, 33,  6, 54, 51, 29, 48, 23,\n",
       "        2, 43, 42, 11, 35, 39, 36, 44, 48, 28, 55,  2, 51, 55, 46,  1, 56,\n",
       "       30, 22, 50,  6, 40, 18, 19, 47,  6, 46, 59, 25, 31, 38,  5, 32, 25,\n",
       "       56, 39, 37, 32, 29, 46, 52, 28, 34, 16, 47, 55, 24, 23, 18, 20,  6,\n",
       "       36, 38, 22, 28, 44, 46, 55, 59, 49, 55, 57, 12, 52, 38, 29,  4, 31,\n",
       "       49, 14, 19, 12, 45, 36, 43, 34, 32, 54, 46, 27,  5,  7, 42, 19, 26,\n",
       "       31, 36, 53, 10, 12, 33, 38,  2, 57, 37, 17, 50, 46, 46, 17, 34, 32,\n",
       "       40, 19, 40,  8, 22, 38, 15, 39,  9, 52, 37, 28, 13, 10, 55, 28, 25,\n",
       "       42, 57, 16, 27, 23,  3, 51, 27, 32, 46, 16, 53, 11, 46, 42, 37, 47,\n",
       "       50,  3, 41, 19, 20, 15,  8,  3, 18,  5, 28, 46, 49, 16, 40, 17, 20,\n",
       "       53, 57,  7, 16, 11, 35, 34, 52, 41, 55,  7, 18, 21, 19, 37, 55, 29,\n",
       "       28, 23, 35, 46, 52, 30, 27, 13,  7, 28, 14,  3, 36, 17, 60, 18,  3,\n",
       "       22,  9, 46, 25, 17, 26, 19, 36, 36, 21,  1, 44, 39, 47, 38,  6, 50,\n",
       "       39, 23, 37, 48, 22, 58, 15, 30, 38, 18, 54,  3, 41, 16,  8, 43, 28,\n",
       "        8, 57, 10, 16,  4, 20, 15, 51, 56, 33, 16, 33, 50, 51,  5, 51, 31,\n",
       "        6,  9, 31, 57, 22,  5, 11, 11, 43,  8,  7, 58, 50, 50, 58, 13, 13,\n",
       "       47, 50, 60, 50, 47, 36, 28, 36, 49,  7, 34, 32,  5,  2, 19, 55, 56,\n",
       "       50, 30, 32, 41, 37, 41, 51, 20, 20, 11, 21, 44, 31, 15, 40, 46, 48,\n",
       "       21, 25, 36, 44, 54, 17, 46, 57, 56, 53, 26, 27, 17,  5, 39, 28,  8,\n",
       "       32, 21, 49, 56, 17, 26, 49, 54, 10,  9,  3, 36, 39, 33, 18, 54, 29,\n",
       "       23, 10, 11, 47, 37, 39, 41, 35, 25, 27,  4, 51, 12, 33, 42, 27, 44,\n",
       "       23,  6, 12, 30, 40, 56, 27,  8, 44, 15, 59, 29, 39, 29, 28,  7, 31,\n",
       "        3, 59,  3, 31, 10, 60, 58, 42, 10, 31, 60, 23,  7, 19, 18, 43, 11,\n",
       "       35,  2, 23, 41, 15, 54,  9, 40, 53, 29, 20, 21, 35, 31, 58,  6, 29,\n",
       "       52, 29, 55, 21, 60, 50, 28, 47, 50, 27, 20, 44, 24,  8, 38, 51, 44,\n",
       "       23,  8, 18, 13, 13,  8, 15,  5, 39, 11, 39, 31, 58, 60, 52, 30, 31,\n",
       "        5, 29, 33, 10, 48, 21, 51, 21, 50, 55, 19, 49, 47, 38, 52,  6, 17,\n",
       "       11, 40, 17, 30,  4,  4, 36, 17, 58, 57, 53, 18, 37, 57, 57, 14, 13,\n",
       "       13, 30, 41, 57, 25, 16, 43, 36, 13, 43, 23, 37, 29,  6, 48, 33, 29,\n",
       "       40, 13, 29, 35, 55, 13, 27, 51, 22, 22, 49,  9, 46, 56, 12, 30, 56,\n",
       "       52, 40, 32, 16, 37, 41, 26,  5, 42, 11, 36, 47, 23, 16, 29, 18, 47,\n",
       "       23, 22, 40, 27, 33, 27, 40, 40, 18, 31,  1,  7, 59, 28, 44, 56, 57,\n",
       "        3, 16, 37, 21, 34, 32, 56, 44, 37, 38,  2, 22, 33, 53, 32, 27, 49,\n",
       "       55, 39, 33, 31, 27, 48, 30, 24, 54, 26, 36, 15, 35, 17, 16,  4, 17,\n",
       "       27, 10, 12, 33,  6, 47, 21,  4, 48, 55, 16, 42, 29, 20, 24, 39, 16,\n",
       "       33, 57, 41,  1, 49, 46,  2, 40, 29, 19, 18, 43, 28, 57, 16, 51,  1,\n",
       "        2, 49, 59, 18,  8, 37, 32, 32, 57, 55,  5, 30, 26, 10, 51,  9, 12,\n",
       "       15, 11, 19, 37, 53, 19,  8, 17, 14,  4, 34, 22, 32, 27, 15,  3, 25,\n",
       "       50,  8, 53, 30, 13, 25, 60, 40, 11, 37,  4, 44, 55, 52, 20, 34,  2,\n",
       "       59, 59, 39, 23, 37, 43,  1, 32, 50, 51,  9, 32,  5, 31,  1, 46, 37,\n",
       "       19, 24, 38, 59,  6, 51, 20,  1, 20,  2, 60, 10, 42, 48, 54, 43, 39,\n",
       "        8, 50, 30, 15,  2,  9,  1, 50, 44, 16, 42, 31, 24, 52, 50,  1, 47,\n",
       "       19, 10, 59, 43, 21, 44, 48, 22, 14, 20, 46, 33, 53, 33, 51,  4, 46,\n",
       "       59, 28, 55, 50, 56, 26, 19, 16, 46, 35, 54, 38, 51])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train[\"label_1\"])\n",
    "X_test_contiguous = np.ascontiguousarray(X_test)\n",
    "y_pred_label1 = clf.predict(X_test_contiguous)\n",
    "y_pred_label1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf0bb2-8b35-4bad-a9d5-203a7000ac2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2b6c68e-9088-4d69-a72d-e4edf48acf7b",
   "metadata": {},
   "source": [
    "# Label_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "76408354-4fde-411a-9be4-eb9bcd123d70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1      0\n",
       "feature_2      0\n",
       "feature_3      0\n",
       "feature_4      0\n",
       "feature_5      0\n",
       "              ..\n",
       "feature_768    0\n",
       "label_1        0\n",
       "label_2        0\n",
       "label_3        0\n",
       "label_4        0\n",
       "Length: 772, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_label_2 = df.dropna(subset=['label_2'])\n",
    "df_label_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9a3178f9-c94d-40ec-b896-f047cc2aad4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_l2 = df_label_2[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]]\n",
    "X_train_l2 = df_label_2.drop(y_train_l2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "37dc7f16-ecc8-4657-ad02-e12fa408c4a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     label_1  label_2  label_3  label_4\n",
       "480        5     25.0        1        6\n",
       "481        5     25.0        1        6\n",
       "482        5     25.0        1        6\n",
       "483        5     25.0        1        6\n",
       "484        5     25.0        1        6"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_l2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3071d2bf-ed33-4a4a-9acb-0a577578df35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "feature_1      0\n",
       "feature_2      0\n",
       "feature_3      0\n",
       "feature_4      0\n",
       "feature_5      0\n",
       "              ..\n",
       "feature_768    0\n",
       "label_1        0\n",
       "label_2        0\n",
       "label_3        0\n",
       "label_4        0\n",
       "Length: 772, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df_label_2 = valid_df.dropna(subset=['label_2'])\n",
    "valid_df_label_2.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "38a2f501-f8f8-4b9d-845c-33f2a0695e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_valid_l2 = valid_df_label_2[[\"label_1\",\"label_2\",\"label_3\",\"label_4\"]]\n",
    "X_valid_l2 = valid_df_label_2.drop(y_train_l2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7568973e-41d5-42e1-ab78-280c6a7f8ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "      <th>label_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    label_1  label_2  label_3  label_4\n",
       "14        5     25.0        1        6\n",
       "15        5     25.0        1        6\n",
       "16        5     25.0        1        6\n",
       "17        5     25.0        1        6\n",
       "18        5     25.0        1        6"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_valid_l2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7f6b86-0442-4f5a-bb42-56fd1bc28b38",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "266fc800-6690-4b2a-afee-4918654d5525",
   "metadata": {},
   "source": [
    "# Use the SVM Model for label_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bd43bc0b-12b8-4d7e-bcca-d4d82f0a92c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.8804347826086957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Linear SVM (one-vs-the-rest)  0.8301630434782609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with linear kernal function  0.8546195652173914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with sigmoid kernal function  0.485054347826087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.873641304347826\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 3  0.873641304347826\n"
     ]
    }
   ],
   "source": [
    "try_svm(X_train_l2,y_train_l2[\"label_2\"],X_valid_l2,y_valid_l2[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783c6d15-7c72-40cc-a1f9-4af9a1e1ce0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e56c835-d47e-4010-a4cc-c013234334d4",
   "metadata": {},
   "source": [
    "# Use the KNN Model for label_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "eb979b72-1a93-4a71-b291-9177aec89f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 3, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.9470108695652174\n"
     ]
    }
   ],
   "source": [
    "try_knn(X_train_l2,y_train_l2[\"label_2\"],X_valid_l2,y_valid_l2[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db35b2b-2216-4b64-8ed5-749caa3a80d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "baea28bd-0ccb-4f7d-bb9a-9fcc22576dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.8872282608695652\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(X_train_l2,y_train_l2[\"label_2\"],X_valid_l2,y_valid_l2[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2635bf-ab37-4f90-9fa8-4fca3f260ede",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "87b6a5e4-afcf-48df-b3ec-42517a2c5f81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.782608695652174\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(X_train_l2,y_train_l2[\"label_2\"],X_valid_l2,y_valid_l2[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d347433d-8b36-4c9d-a673-40c600efbf87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "ebfaf014-7e55-4744-894f-a02d3d349f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.7540760869565217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver newton-cg 0.7540760869565217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver sag 0.7540760869565217\n",
      "Accuracy Score of Logistic Regression with solver saga 0.7540760869565217\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "try_logistic(X_train_l2,y_train_l2[\"label_2\"],X_valid_l2,y_valid_l2[\"label_2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89cc7e6-cd5f-4e6b-81b1-d29372f8af30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc249a5c-0f96-4134-b488-b5afc2b2b5a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25319835-9274-42c9-a421-3a01049852b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dbf54b-ac3d-4c8a-8879-3c15f2cfafd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "257352c0-9e80-4636-a2d6-892d999af368",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f63092a4-fc5b-4892-890d-fc306590d665",
   "metadata": {},
   "source": [
    "For label_4 we get best accuracy(0.94701) when using the KNN model. \n",
    "So we can use this methods to predict the values for test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e8ca8-16ea-4b9e-9c1f-a1e9ba85811b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a37f2751-2e88-4ae0-9297-e6a4c3040a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([22., 25., 30., 27., 29., 30., 27., 33., 23., 22., 26., 25., 27.,\n",
       "       26., 23., 26., 28., 25., 22., 29., 33., 24., 29., 22., 61., 26.,\n",
       "       28., 23., 25., 26., 23., 30., 30., 24., 28., 24., 24., 25., 26.,\n",
       "       25., 26., 23., 25., 30., 31., 22., 26., 32., 25., 23., 22., 24.,\n",
       "       29., 27., 23., 23., 30., 34., 28., 25., 30., 23., 23., 26., 28.,\n",
       "       25., 25., 25., 22., 32., 33., 28., 61., 30., 23., 31., 26., 26.,\n",
       "       27., 26., 34., 32., 23., 23., 26., 26., 31., 23., 26., 29., 29.,\n",
       "       31., 25., 23., 27., 30., 31., 25., 27., 29., 23., 22., 26., 22.,\n",
       "       24., 36., 26., 26., 32., 25., 27., 27., 26., 24., 30., 30., 26.,\n",
       "       25., 25., 26., 26., 26., 41., 33., 32., 28., 29., 35., 34., 25.,\n",
       "       28., 27., 36., 23., 28., 22., 29., 27., 30., 31., 23., 25., 26.,\n",
       "       31., 23., 30., 30., 23., 33., 30., 29., 27., 23., 24., 31., 30.,\n",
       "       23., 25., 28., 23., 31., 25., 25., 28., 30., 25., 30., 26., 26.,\n",
       "       25., 23., 27., 31., 30., 33., 24., 25., 34., 28., 23., 27., 25.,\n",
       "       26., 23., 27., 23., 28., 28., 28., 24., 30., 34., 28., 31., 27.,\n",
       "       25., 28., 31., 31., 22., 26., 27., 25., 31., 33., 35., 25., 22.,\n",
       "       26., 22., 25., 22., 26., 26., 30., 61., 29., 23., 32., 25., 24.,\n",
       "       29., 28., 27., 26., 33., 29., 28., 28., 32., 25., 27., 25., 30.,\n",
       "       30., 41., 31., 28., 41., 34., 36., 30., 23., 25., 28., 26., 24.,\n",
       "       26., 30., 26., 24., 26., 25., 26., 26., 25., 35., 26., 27., 33.,\n",
       "       25., 33., 25., 31., 41., 27., 29., 24., 24., 29., 27., 27., 23.,\n",
       "       24., 27., 24., 23., 22., 28., 22., 26., 27., 25., 23., 25., 25.,\n",
       "       23., 23., 27., 24., 28., 23., 30., 27., 30., 26., 25., 25., 31.,\n",
       "       26., 61., 26., 28., 26., 28., 26., 26., 22., 22., 61., 27., 26.,\n",
       "       30., 27., 24., 24., 22., 23., 26., 25., 29., 28., 25., 23., 26.,\n",
       "       26., 24., 26., 22., 26., 27., 36., 35., 31., 22., 29., 26., 25.,\n",
       "       27., 23., 28., 36., 33., 23., 27., 29., 30., 24., 22., 31., 23.,\n",
       "       26., 26., 29., 29., 23., 61., 28., 25., 26., 28., 26., 24., 31.,\n",
       "       41., 61., 28., 31., 23., 29., 23., 28., 27., 26., 31., 31., 31.,\n",
       "       26., 36., 27., 29., 29., 36., 26., 27., 28., 27., 23., 25., 31.,\n",
       "       33., 24., 25., 28., 30., 28., 27., 26., 26., 24., 26., 25., 26.,\n",
       "       24., 26., 29., 25., 23., 34., 23., 23., 26., 27., 24., 28., 23.,\n",
       "       24., 31., 25., 61., 26., 41., 32., 26., 61., 28., 41., 25., 27.,\n",
       "       27., 41., 28., 25., 29., 33., 29., 26., 29., 27., 34., 28., 26.,\n",
       "       25., 23., 26., 36., 26., 26., 26., 26., 24., 23., 23., 26., 23.,\n",
       "       32., 34., 25., 26., 33., 26., 26., 28., 23., 23., 22., 28., 29.,\n",
       "       27., 24., 25., 29., 27., 27., 31., 27., 27., 28., 41., 27., 22.,\n",
       "       30., 31., 22., 27., 31., 28., 27., 23., 25., 26., 26., 23., 26.,\n",
       "       27., 23., 26., 23., 27., 31., 26., 33., 33., 26., 35., 30., 24.,\n",
       "       26., 28., 24., 34., 26., 23., 30., 27., 30., 22., 25., 29., 33.,\n",
       "       22., 23., 28., 30., 23., 25., 23., 28., 33., 26., 31., 26., 31.,\n",
       "       26., 26., 25., 26., 30., 27., 31., 28., 61., 24., 27., 31., 26.,\n",
       "       27., 26., 25., 23., 24., 61., 27., 32., 25., 33., 26., 24., 23.,\n",
       "       31., 23., 23., 26., 26., 26., 31., 26., 28., 26., 27., 22., 22.,\n",
       "       28., 24., 26., 30., 23., 26., 31., 36., 26., 26., 25., 23., 26.,\n",
       "       23., 26., 23., 30., 29., 23., 25., 26., 29., 26., 26., 27., 30.,\n",
       "       30., 26., 30., 25., 26., 23., 23., 25., 31., 23., 27., 30., 26.,\n",
       "       30., 25., 26., 31., 25., 41., 27., 23., 23., 27., 23., 27., 28.,\n",
       "       22., 26., 23., 35., 26., 28., 33., 23., 27., 24., 23., 41., 26.,\n",
       "       31., 23., 25., 33., 23., 31., 28., 31., 22., 24., 41., 24., 28.,\n",
       "       27., 22., 27., 26., 33., 30., 23., 61., 23., 34., 25., 25., 25.,\n",
       "       31., 31., 29., 27., 27., 31., 30., 23., 24., 26., 35., 23., 25.,\n",
       "       26., 30., 30., 31., 23., 26., 32., 31., 25., 26., 25., 24., 23.,\n",
       "       25., 27., 36., 29., 26., 27., 31., 29., 41., 24., 28., 28., 25.,\n",
       "       35., 30., 24., 61., 30., 25., 26., 26., 34., 24., 30., 23., 23.,\n",
       "       36., 22., 31., 26., 61., 26., 33., 23., 25., 28., 26., 24., 26.,\n",
       "       26., 23., 30., 31., 28., 23., 24., 24., 22., 23., 30., 30., 24.,\n",
       "       27., 32., 26.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 3\n",
    "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_model.fit(X_train_l2, y_train_l2[\"label_2\"])\n",
    "X_test_contiguous = np.ascontiguousarray(X_test)\n",
    "y_pred_label2 = knn_model.predict(X_test_contiguous)\n",
    "y_pred_label2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998a977a-ca47-47b5-baa6-db12dd8d6f81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "65fdfaf7-c0b1-4239-ba7b-eb26abff0ff1",
   "metadata": {},
   "source": [
    "# Label_3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b79a42-ae24-421b-9b9f-3e5bfc4c5e49",
   "metadata": {},
   "source": [
    "# Use the SVM Model for label_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "986adc72-7dc9-4a4f-b88e-09e5f3c0d847",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.9986666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Linear SVM (one-vs-the-rest)  0.9986666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with linear kernal function  0.9986666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with sigmoid kernal function  0.9346666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.9986666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 3  0.9986666666666667\n"
     ]
    }
   ],
   "source": [
    "try_svm(X_train,y_train[\"label_3\"],X_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1d229e-a3b8-40d9-8c6a-dfc0643242f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8269ac7-921f-45b5-b0bd-c3371933dcfa",
   "metadata": {},
   "source": [
    "# Use the KNN Model for label_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "450c81d8-53d4-426f-b492-616896a33c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.9973333333333333\n"
     ]
    }
   ],
   "source": [
    "try_knn(X_train,y_train[\"label_3\"],X_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51538fad-55c7-4ef2-9f58-02d6ad60fa4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "6eb1e765-777f-4568-a23c-f0724eda2b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.996\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(X_train,y_train[\"label_3\"],X_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea9a0f3-2bfd-4ef1-a56e-85f01614d278",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7d5a479-b96c-46d3-b58e-70e83c91a7de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4adca5f8-c833-422d-8829-08ba993d9b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.9613333333333334\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(X_train,y_train[\"label_3\"],X_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5069bac5-94ed-489c-834d-51e394ad555b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e75d91bb-88e6-477c-a427-bf45d889ecc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.9986666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver newton-cg 0.9986666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver sag 0.9986666666666667\n",
      "Accuracy Score of Logistic Regression with solver saga 0.9986666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "try_logistic(X_train,y_train[\"label_3\"],X_valid,y_valid[\"label_3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e79f8c-a6af-4309-b15b-fc59ea8f22e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5fa039-ce91-482a-bed7-d0079a9c1d5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f584d295-c1e7-4c0a-8014-1841e2019df2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "25ccfc58-2e58-4092-8a72-bb193b9a1c5d",
   "metadata": {},
   "source": [
    "For label_3 we get best accuracy(0.9986) when using the SVM with default settings, Linear SVM, SVM with linear kernal, SVM with polynomial kernal and all logistic models.\n",
    "So we can use any of these methods to predict the values for test data set. I am going to use Linear SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0260a0ca-1405-45a0-a76b-852e1e5dac8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train[\"label_3\"])\n",
    "X_test_contiguous = np.ascontiguousarray(X_test)\n",
    "y_pred_label3 = clf.predict(X_test_contiguous)\n",
    "y_pred_label3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24b7404b-dc1a-4858-a617-662bc9337166",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6715d-e6fe-4ab1-9d63-603cec30970c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5632ce18-59e8-45af-945a-9521bd579607",
   "metadata": {},
   "source": [
    "# Label_4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828e8c75-52b6-4d24-b179-b4264fdefe56",
   "metadata": {},
   "source": [
    "# Use the SVM Model for label_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f8abd250-10f8-4bbe-a944-f43b294fe6d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with default settings (RBF - exponential kernal)  0.9426666666666667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but LinearSVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Linear SVM (one-vs-the-rest)  0.9413333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with linear kernal function  0.9573333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with sigmoid kernal function  0.7653333333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 2  0.9413333333333334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but SVC was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of SVM with polynomial kernal function with degree 3  0.9413333333333334\n"
     ]
    }
   ],
   "source": [
    "try_svm(X_train,y_train[\"label_4\"],X_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ed0b6c-ba8c-4031-b897-3043d54dbe05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9d99bf1-bead-4bf9-a6c7-c198d0d21db2",
   "metadata": {},
   "source": [
    "# Use the KNN Model for label_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "34fea2dc-6a3b-4b97-a529-2a67e378f662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best Hyperparameters: {'n_neighbors': 7, 'weights': 'distance'}\n",
      "Accuracy for KNN 0.9626666666666667\n"
     ]
    }
   ],
   "source": [
    "try_knn(X_train,y_train[\"label_4\"],X_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da144aea-9798-47d1-af73-17423452eadb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1179495b-7445-4d47-a98e-b5d7ebac93ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of XG Boost 0.92\n"
     ]
    }
   ],
   "source": [
    "try_xgBoost(X_train,y_train[\"label_4\"],X_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9c786e-d39a-468e-83e7-8ccdc1a0f8c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d58cc8ef-024f-4c4e-9849-4d60e79e9041",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Random Forest 0.7666666666666667\n"
     ]
    }
   ],
   "source": [
    "try_random_forest(X_train,y_train[\"label_4\"],X_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fa4c01-095a-46a9-a88c-19f111809a30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4aa2a953-d7eb-40fa-a45a-f0120db64906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver lbfgs 0.9306666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver newton-cg 0.9306666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score of Logistic Regression with solver sag 0.9306666666666666\n",
      "Accuracy Score of Logistic Regression with solver saga 0.9306666666666666\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "try_logistic(X_train,y_train[\"label_4\"],X_valid,y_valid[\"label_4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6db6b09f-d785-4c9d-8533-765315730aac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5ef0ee-56e3-4648-bff6-d7d319ff56d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b07cf-7184-4c25-8413-401c125ccb3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9a3206b4-da69-40a1-9926-8b956b72b072",
   "metadata": {},
   "source": [
    "For label_4 we get best accuracy(0.96266) when using the KNN model\n",
    "So we can use this methods to predict the values for test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dcc0ea90-e4d8-4161-b0bc-0786bd0b77d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sakeerthan/.local/lib/python3.8/site-packages/sklearn/base.py:465: UserWarning: X does not have valid feature names, but KNeighborsClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 2,  8,  6,  6,  6,  6,  6,  6,  6,  2,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  5,  0,  6,  2,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  8,  6,  3,  6,  6,  6,  1,  6, 12,  6,  0,  1,\n",
       "        6,  6,  7,  0,  6,  6,  5,  6,  6,  6,  3,  6,  2,  6,  6,  6,  6,\n",
       "        6, 12,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  5, 12,  6,  6,  6,\n",
       "        6, 12,  4,  6,  6,  6,  6,  6,  0,  6,  6,  6,  6,  6,  0,  4,  2,\n",
       "        6,  6,  6,  6,  6,  6, 12,  6,  6,  7,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6, 12,  9,  6, 11,  5,  6,  6,  6,  6,  6,  6,  1,\n",
       "        0,  6,  6,  7,  6,  6,  6,  7,  0,  6,  6,  6,  6,  6,  0,  7,  3,\n",
       "        6,  6, 10,  4,  6,  9,  6,  6,  8,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  7,  6,  6,  6,  6,  5,  9,  6,  6,  8,  6,  4,  7,  6,  6,\n",
       "        6,  6,  2,  6,  5,  6,  7,  6,  6,  6, 12,  6,  6,  6, 13,  8,  6,\n",
       "        6, 11,  6,  1,  6,  2,  6,  6,  6,  6,  6,  6,  6,  3, 12,  6,  6,\n",
       "        6,  6,  7,  6,  6,  6,  9,  6, 12,  8,  6,  6, 10,  6,  6,  6,  6,\n",
       "        6,  5,  6,  6,  6,  6,  9,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6, 11,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        3,  6, 13,  6,  3,  6,  6,  6,  6,  6,  6,  0,  6,  6,  4,  6,  6,\n",
       "        6,  6,  0, 10,  7, 10,  6,  6,  6,  6,  6,  6,  6,  9,  6,  6,  6,\n",
       "        6,  1,  6,  6,  6,  6,  6,  6,  6,  6,  2,  6,  6,  6,  6,  6,  6,\n",
       "        0,  6,  6,  6,  6,  2,  6,  6,  6, 11,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  3,  7,  6, 10,  2,  1,  7,  6,  6,  6,  6,  0,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  7,  6,  6,  9,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6, 13,  6,  6,  6,  6, 13,  6,  6,  6,  8,  6,  6,\n",
       "        7,  6,  6, 10,  9,  6,  6,  6,  6,  6,  6,  6,  2,  6,  6,  6,  6,\n",
       "        5,  6,  6,  6,  6,  6,  6,  2,  6,  7,  6,  6,  2,  6, 12,  6,  6,\n",
       "        6,  6,  8,  6,  6,  6,  9,  6,  6,  6,  6,  6,  6, 13,  5,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  4,  6,  3, 12,  5,  6,  6,\n",
       "        6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  8,  7,  6,  6, 12,  6,\n",
       "        6,  6, 10,  6,  1,  6,  6,  6,  6,  6,  6,  7,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  2,  6,  7,  6,  6,  6,  6, 11,  6,  6,  6,  6,  6,\n",
       "        5,  6,  0,  6,  7, 10,  2,  6,  0,  6,  6,  3,  6,  6,  6,  8,  3,\n",
       "        6,  6,  6, 12,  6,  6,  6,  6,  8,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  7,  6,  6,  0,  6,  6,  7, 12,  6,  6,  6,  6,  0,  7,  6,\n",
       "        6,  6,  6,  6,  7,  6,  6,  2,  6,  2,  6,  9,  2,  6,  6,  6,  6,\n",
       "        7,  6,  6,  6,  6,  3,  6,  6,  6,  6,  6,  0,  6,  6,  2,  6,  6,\n",
       "        6,  6, 10,  6,  6,  6,  6,  6,  6,  4,  8,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  8,  6,  7,  0,  0,  6,  6,  6,  6,  2,  8,  6, 11,  6,\n",
       "        9,  6,  4,  7,  6,  4,  6,  6, 12,  6,  6,  6,  0,  7,  9,  6,  1,\n",
       "        6,  6,  6,  6,  6,  1, 13,  6,  6,  7,  6,  6,  6,  5,  6,  6,  6,\n",
       "        6,  6,  6,  6,  7,  6,  6,  0,  6,  6, 11,  0,  6,  6,  6,  6,  6,\n",
       "        4,  2, 12,  6,  6,  6,  6,  6,  6,  6, 13,  6,  0,  6,  6,  6,  6,\n",
       "        6,  6,  6,  9,  6, 11,  6,  6,  6,  6,  6,  6,  2,  5,  6,  6,  3,\n",
       "        4,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
       "        6,  6,  6,  6,  6,  2,  6,  6,  6,  2,  6, 12,  6])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = 7\n",
    "knn_model = KNeighborsClassifier(n_neighbors=k)\n",
    "knn_model.fit(X_train, y_train[\"label_4\"])\n",
    "X_test_contiguous = np.ascontiguousarray(X_test)\n",
    "y_pred_label4 = knn_model.predict(X_test_contiguous)\n",
    "y_pred_label4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9589d0c1-acaf-4c6d-9e98-de206b4d9f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "45799eab-29d9-4ec2-a06a-2ca904a46af0",
   "metadata": {},
   "source": [
    "# Final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4512744f-1f4f-4bc7-b027-cd6293b6df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.concat([pd.Series(test_df['ID']), pd.Series(y_pred_label1, name='label_1'), pd.Series(y_pred_label2, name='label_2'), pd.Series(y_pred_label3, name='label_3'), pd.Series(y_pred_label4, name='label_4')], axis=1)\n",
    "output_file_name = \"190541R_lab_2.csv\"\n",
    "final_df.to_csv(output_file_name, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e593181-e2ef-40c5-99e3-2467a1ef333c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1babb03b-4d4c-478e-9a57-a5dde6ceb892",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
